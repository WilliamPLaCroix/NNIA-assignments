{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwL-VcGY6shN"
   },
   "source": [
    "# NNIA Assignment 4\n",
    "**DEADLINE: 1.12.2023 0800 CET**\n",
    "- Name & ID 1 (CMS username):\n",
    "- Name & ID 2 (CMS username):\n",
    "- Hours of work per person:\n",
    "\n",
    "# Submission Instructions\n",
    "**IMPORTANT** Please make sure you read the following instructions carefully. If you are unclear about any part of the assignment, ask questions **before** the submission deadline. All course-related questions can be addressed on the course **CMS Forum**.\n",
    "\n",
    "* Assignments are to be submitted in a **team of 2-3**. It is fine to submit first **2** assignments without a team, but starting from the **3rd** assignment it is not allowed.\n",
    "* Please include your **names**, **ID's**, **Teams usernames**, and **approximate total time spent per person** at the beginning of the Notebook in the space provided\n",
    "* Make sure you appropriately comment your code wherever required.\n",
    "* Do **not** submit any data or cache files (e.g. `__pycache__`).\n",
    "* Upload the **zipped** folder (`.zip` is the only accepted extension) in **CMS**.\n",
    "* Only **one** member of the group should make the submission.\n",
    "* **Important** please name the submitted zip folder as: `Name1_id1_Name2_id2(_Name3_id3).zip`. The Jupyter Notebook should also be named: `Name1_id1_Name2_id2.ipynb`. This is **very important** for our internal organization repeatedly students fail to do this.\n",
    "\n",
    "<font color=\"red\">Failure to follow the above instructions will result in point penalties at the discretion of the instructors.</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 Manual Regression (5 points)\n",
    "\n",
    "In this exercise, we will be working with the [California Housing Dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset), one of the real world datasets available in the scikit-learn library. Familiarize yourself with the dataset documentation to understand its structure and the variables included."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Dataset Overview\n",
    "Begin by exploring the [documentation](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset). Answer the following questions:\n",
    "1. According to this dataset, how many features influence the housing prices in California? List these features.\n",
    "2. Identify which feature(s) you believe are the most influential in determining housing prices, and explain your reasoning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 <font color=\"red\">To Do</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Manual Regression\n",
    "\n",
    "Now that you are a bit more familiar with the data and the features. This exercise aims to develop some intuition behind regressions by manually adjusting the parameters (coefficients and intercept) in the model. The functions below all perform regression (predicting a real value) but they are far from perfect. Your goal is to improve the four functions from the initial ones in the `code cells` as follows:\n",
    "\n",
    "1. `hand_base` should serve as a baseline. The constraint is that it should only return a *single (constant) number* for all values. In other words, this is a model with no adjustable parameters. However, for the dataset there exists a unique value that minimizes the Mean Squared Error (MSE). Which one is it? (0.5 points) \n",
    "2. `hand_linear` should be a reasonable *linear* function that utilizes the input feature(s). Note that it should be strictly linear, that is in the form $\\sum \\lambda_i x_i+\\lambda_{const}$ where $\\lambda_k$ and $\\lambda_{const}$ are the coefficients and intercept that you can estimate from the given data by *trial and error*. Your estimates should be reasonable, i.e. definitely better than `hand_base`. Do this exercise before proceeding to the next function where you will obtain the coefficients and intercepts from fitting a Linear Regression model using *sklearn*. We will award full points based on any justified solution that's better than `hand_base`. Make sure that you read what the features mean and argue why you chose the specific formula. (1 point) (Note: we are *not* asking you to compute the coefficients and intercept, but rather play around with adjusting the coefficients and intercept manually to arrive at your best estimate.)\n",
    "3. `auto_linear`, obtain the coefficients and intercept from fitting a Linear Regression model using `sklearn`.\n",
    "(Consult [sklearn Linear Regression Documention](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) on how to obtain the model's coefficients and intercept.) (1 point)\n",
    "\n",
    "4. `hand_complex` does not have any restriction on the content of the function. It can contain polynomial relationships (e.g. `x[0]*x[0]`), `if-else` statements, etc.) Now that you have both your handcrafted model and the one from `sklearn`, improve upon either of the models (or you can start with the parameters in the `auto_linear` model) so that the performance of the `hand_complex` is better than `auto_linear`.\n",
    "What are the disadvantages of this more complex approach apart from the difficulty of creating it? (Hint: think about unseen data.)\n",
    "\n",
    "Always comment on what led you to select the specific values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 <font color=\"red\">To Do</font>\n",
    "\n",
    "Modify the functions in the `code cell` below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "MSE Hand-Base: 5.61\n",
      "MSE Hand-Linear: 133.07\n",
      "MSE Auto-LR: 133.07\n",
      "MSE Hand-Complex: 20.43\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "housing_x = housing.data\n",
    "housing_y = housing.target\n",
    "\n",
    "print(\"Features\", housing.feature_names)\n",
    "\n",
    "def hand_base(_x):\n",
    "  # TODO: choose better single value\n",
    "  return 0\n",
    "\n",
    "def hand_linear(x):\n",
    "  # TODO: make me better but only linearly\n",
    "  return 2*x[0]-0.5*x[1]-0.1\n",
    "\n",
    "# TODO:\n",
    "# 1. Fit LinearRegression\n",
    "# 2. Report training MSE\n",
    "# 3. Examine the coefficients and intercept and use them for the `auto_linear` function\n",
    "# <https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html>\n",
    "\n",
    "def auto_linear(x):\n",
    "  # TODO: use coefficients from your linear regression\n",
    "  return 2*x[0]-0.5*x[1]-0.1\n",
    "\n",
    "def hand_complex(x):\n",
    "  # TODO: make me better than the auto_linear function\n",
    "  if x[0] < 0.5:\n",
    "    return 0.1*x[1]\n",
    "  else:\n",
    "    return 0.2*x[1]\n",
    "\n",
    "print(f\"MSE Hand-Base: {mse(housing_y, [hand_base(x) for x in housing_x]):.2f}\")\n",
    "print(f\"MSE Hand-Linear: {mse(housing_y, [hand_linear(x) for x in housing_x]):.2f}\")\n",
    "print(f\"MSE Auto-LR: {mse(housing_y, [auto_linear(x) for x in housing_x]):.2f}\")\n",
    "print(f\"MSE Hand-Complex: {mse(housing_y, [hand_complex(x) for x in housing_x]):.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T06:04:42.969887Z",
     "start_time": "2023-11-22T06:04:41.624255Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 Overfitting (3 points)\n",
    "Overfitting happens when the model capacity is too high and there is no proper regularization applied. Figure 1 and Figure 2 show two different classification boundaries for a binary classification problem, where the blue points and the red points represent the training data consisting out of two classes. Please answer the following questions. You may find the relevant content in the 'Deep Learning Book' helpful for this: [5.2 Capacity, Overfitting and Underfitting](https://www.deeplearningbook.org/contents/ml.html).  <br>\n",
    "\n",
    "| --- | --- |\n",
    "| ![Figure 1](fig1.png) | ![Figure 2](fig2.png) |\n",
    "| Figure 1 | Figure 2 |\n",
    "\n",
    "\n",
    "1. Which classification boundary correspond to the overfitting and the underfitting, respectively? Justify your answer in 1-2 sentences. (0.5 pt)\n",
    "2. Explain the terms overfitting, underfitting, and model capacity with the help of Figure 1 and Figure 2. (1.5 pt)\n",
    "3. What happens to the training error and validation error when a model overfits? Explain. (1 pt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 Evaluation Metrics (2 points)\n",
    "\n",
    "In the lecture slides (Chapter 4, page 9 \"The Performance Measure $P$\"), there is some brief discussion about evaluation metrics. Additionally, watch [this video about evaluation metrics](https://youtu.be/wpQiEHYkBys). Discuss the differences between Accuracy, Precision, Recall, F1, MCC (Mathews Correlation Coeffcient):\n",
    "\n",
    "1. How are they calculated? (0.5 points)\n",
    "2. In which case can a model get the perfect score? (0.5 points)\n",
    "3. Give examples of situations when you would prefer one over the others. (0.5 points)\n",
    "4. Choose one metric. In which case can a model get a very high score even though we would judge its performance to be bad? I.e. how can the model cheat the metric? (0.5 points)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
